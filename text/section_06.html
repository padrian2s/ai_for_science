<div class="page-content">
  <h2>Section 6: Barish &mdash; Multi-Messenger Astronomy &amp; AI's Limits</h2>

  <div class="transcript">
    <span class="speaker speaker--guest">Barry Barish:</span>
    <p>This is the first and maybe most important event we've seen in multi-messenger astronomy: the collision of two neutron stars. On the left you see three or four plots. The bottom one is gravitational waves &mdash; a time-frequency plot. The little line on that plot is the gravitational wave signal as seen in LIGO, and it was very clean. If you project upward in time, these are satellites that were looking at high-energy gamma rays. Within about one and a half to two seconds, they saw a signal as well. That's what gave us the confidence to alert the astronomical community.</p>

    <p>A side remark: we expect that when gravitational waves are emitted &mdash; which has to do with gravitational interaction &mdash; they're going to arrive slightly before any nuclear physics would emit photons, because that happens after the merger. So within a couple seconds is reasonable. But we know from analyzing this event that it came from a galaxy 150 million light-years away. 150 million light-years is 1.5 times 10 to the 15 seconds. So within something like one part in 10 to the 15, we showed just in this little plot that light and gravitational waves travel at the same speed.</p>

    <p>We alerted the whole community. They could identify what galaxy it was in. It was then observed across all frequencies &mdash; out to days, when you see the radio waves. That whole picture was analyzed, which is the power of multi-messenger astronomy: understanding what happens when two neutron stars collide. And it fits a model in the literature called a kilonova.</p>

    <p>Everyone's heard of a supernova &mdash; when a star burns up its fuel and collapses. A kilonova is different. Once we saw it, you can calculate what actually happens inside the kilonova, and it solves a problem that has nothing to do with physics directly &mdash; a geology problem I remember from graduate school. The universe is made out of hydrogen and helium, dominantly. Stars have a few heavier elements and burn by the fusion process. So we make heavier elements through fusion in stars, but the fusion process only works up to iron. We couldn't explain by that simple argument where our favorite metals got into the Earth &mdash; like gold and platinum. The old argument about where heavy elements came from is probably wrong. The right answer is that at earlier times, neutron stars collided and made these heavy elements. In this one kilonova event, it produced about 100 Earth-masses of gold. That's an illustration of how sometimes the science you get can move a long way from what you're doing, if you keep your eyes open.</p>

    <p>We now use modern techniques like squeezed light &mdash; a quantum effect &mdash; to make the instrument even more sensitive. Deep in the modeling of how we implement something like squeezed light, we use AI techniques. Even though it was a big success to detect gravitational waves, we've been able to improve dramatically since then through more modern interferometry techniques. We now have approaching 300 events. With each observing run &mdash; run one, run two, run three &mdash; we improve the instrument and the detection rate gets higher.</p>

    <p>Not only do we get more events, but they're much cleaner. I've picked a recent event &mdash; less than a year old &mdash; that has more or less the same parameters as the first event we ever saw. But the first event has a lot of noise, and this new one has very little. That enables us to test fundamental theorems &mdash; like one by Hawking &mdash; that we couldn't test with the earlier data.</p>

    <p>Now we have hundreds of events and we can compare with various astronomical models. On general relativity: so far we've seen no violations, and we're able to set a limit on whether there's something called a graviton at a very small level &mdash; 10 to the minus 23.</p>

    <p>On the bottom left is something interesting: as you might expect in a few hundred events, we have some we can't really explain. We know that neutron stars &mdash; fundamental objects in the sky &mdash; are about 1.4 times the mass of the Sun. Heavier than that, the only objects we know about are black holes. And a black hole can only exist if it's heavier than some limit, which is typically about six solar masses. So between 1.4 and six solar masses, there shouldn't be anything. But we have several events in that range. We're not sure yet whether that means anything, but that's what we have.</p>

    <p>In terms of AI and machine learning, we're using it extensively to help figure out how to make a better detector. It's incremental &mdash; we use it for optical design, for signal processing optimization, and it's a central tool in all the engineering design work. We have a concept now for a next-generation detector, though in the present environment it's not being proposed for funding because the funding agencies are constrained.</p>

    <p>One last thing, which for me is maybe the heart of the problem: we would like, ever since I was a student, to figure out how the universe began and how it evolved at early times. We don't have good tools for that. The best tool we have is the cosmic microwave background &mdash; a kind of photograph of what the universe was like 380,000 years after the Big Bang. Earlier than that is a puzzle. The universe seemed to have grown very quickly &mdash; something people call inflation &mdash; and we can't probe that directly. Gravitational waves could potentially go back to the very earliest moments of creation, but they'd be at much lower frequencies than what we currently detect. There's a big European project, funded to put gravitational wave detectors in space around 2035, which would look at these lower frequencies. LIGO works in the audio band &mdash; coincidentally the frequency range where the Earth is quiet enough for us. Evolution picked the same band for our ears. But in space, you can go to much lower frequencies where there's much more to discover.</p>

    <span class="speaker speaker--host">Audience Member:</span>
    <p>Einstein predicted gravitational waves in 1915, and it took literally 100 years &mdash; 2015 &mdash; before you detected them. What surprised you the most?</p>

    <span class="speaker speaker--guest">Barry Barish:</span>
    <p>We're just scratching the surface. We can see the collisions and mergers of neutron stars and black holes &mdash; that's not a huge surprise. But we don't know where these black holes came from. The biggest question we have now is: what is the origin of these black holes? There are enormous black holes at the centers of galaxies, but these are lighter &mdash; maybe 100 times the mass of our Sun. Were they primordial, made when the universe began? Were they formed by some dynamical mechanism early on? Or did they come from the collapse of heavy stars? The most popular view is that they came from heavy stars burning up their fuel and collapsing. The problem is that we see some that are too heavy to explain that way. Stars heavier than about 50 times the mass of our Sun are unstable, yet we see events closer to 100 solar masses. That creates a problem.</p>

    <span class="speaker speaker--host">Audience Member:</span>
    <p>You mentioned denoising briefly. How does regular mathematics play a role &mdash; things like advanced signal processing?</p>

    <span class="speaker speaker--guest">Barry Barish:</span>
    <p>Advanced mathematics, if it includes solving Einstein's equations especially in the strong-field limit &mdash; certainly yes. To understand the noise, the non-Gaussian features of it, we use advanced modeling as well.</p>

    <span class="speaker speaker--host">Audience Member:</span>
    <p>Coming from another physicist &mdash; throughout your talk, you said there have been no real AI advances in physics. What do you think is the barrier, and what does AI need to do to surmount it?</p>

    <span class="speaker speaker--guest">Barry Barish:</span>
    <p>Ideally, we have to find the connection between the great power we have in AI and statistics. The fact that those are two completely separate topics at the present time &mdash; that's the problem. How do you get them close enough to talk to each other, so that we can use some technique that gives us a level of confidence that isn't just totally a black box, like nested neural networks? That's the challenge, I think.</p>

    <span class="speaker speaker--host">Audience Member:</span>
    <p>You made this important point about discoveries in physics relying on old-fashioned statistics because we can quantify uncertainty precisely. But in areas where there are very complex phenomena and the data itself is complex &mdash; like ocean turbulence, shocks in galaxies, or large-scale structure maps of the universe &mdash; there's another way. You generate forward-model simulations, many realizations of the noise and the uncertain physics, and by comparing those with measurements you can get a pretty good uncertainty estimate. What's interesting sociologically is that I polled cosmologists at a recent conference: just over half said that if a result came out of this process, they wouldn't believe it no matter what.</p>

    <span class="speaker speaker--guest">Barry Barish:</span>
    <p>But I think we are at that transition point. It was only just over half.</p>

    <span class="speaker speaker--host">Audience Member:</span>
    <p>It's not epsilon &mdash; it's 50%.</p>

    <span class="speaker speaker--host">Audience Member:</span>
    <p>Regarding parameter estimation that takes hours or even months for gravitational wave candidates: do you think next-generation data centers would help speed that up? And could we move computation to space to reduce latency?</p>

    <span class="speaker speaker--guest">Barry Barish:</span>
    <p>We are moving instruments to space. There's a big European project, funded to put gravitational wave detectors in space around 2035 &mdash; one of the cornerstone missions in Europe. NASA has a tiny role in it. It's very complementary to what we do and moves toward the ultimate goal of very low-frequency detection, where you can look at the early universe.</p>

    <span class="speaker speaker--host">Audience Member:</span>
    <p>The foundation of large language models is statistics, probability, and prediction from the sciences. So where's the gap between what they're doing and the statistics you're talking about?</p>

    <span class="speaker speaker--guest">Barry Barish:</span>
    <p>In our case, we have to get to the level where we give some probability that something is right or wrong. If we want to tell something like whether it was a pion or a kaon that went through a detector, we give a statistical probability for each. If the difference is large enough, we decide we know &mdash; or we make a better instrument. Traditionally, that's become the main barrier for using nested neural networks for particle identification, even though they're probably better at it. We don't have the confidence we rely on. We have to either adapt away from statistics or find some other way. But this reliance on statistics is what keeps us from moving forward as fast as we might. We need to find some way to bridge that gap.</p>
  </div>

  <div class="commentary">
    <h3>Explained Simply</h3>

    <div class="commentary-section">
      <h4>What Is Multi-Messenger Astronomy?</h4>
      <p>For most of human history, we studied the universe with just one "sense" &mdash; visible light. Over the 20th century, we added other senses: radio waves, X-rays, gamma rays, and neutrinos. Gravitational waves are the newest sense. Multi-messenger astronomy means observing the same cosmic event with multiple types of signals simultaneously. When LIGO detects gravitational waves from a neutron star collision, it alerts observatories around the world so they can point their telescopes at the same spot and observe the event in light, radio, gamma rays, and more. Each "messenger" reveals different information about what happened, just like hearing and seeing an explosion tells you more than either one alone.</p>
    </div>

    <div class="commentary-section">
      <h4>Where Does Gold Come From?</h4>
      <p>This is one of the most delightful findings Barish describes. Stars create heavier elements through nuclear fusion &mdash; hydrogen becomes helium, helium becomes carbon, and so on up the periodic table. But fusion stops working at iron. So where do elements heavier than iron come from &mdash; things like gold, platinum, and uranium? The old answer was "supernovae," but that never fully worked. The new answer, confirmed by this neutron star collision, is kilonovae: when two neutron stars smash together, the extreme conditions forge these heavy elements and scatter them into space. A single kilonova event produced about 100 Earth-masses worth of gold. Every gold ring, every gold bar on Earth was forged in an ancient neutron star collision billions of years ago.</p>
    </div>

    <div class="commentary-section">
      <h4>Why Physicists Need Statistical Significance</h4>
      <p>Barish keeps returning to a central tension: in physics, you must prove your result is real, not a fluke. The standard is "five sigma" &mdash; meaning there's only about a 1-in-3.5-million chance that what you're seeing is random noise. To reach that standard, physicists need to calculate precise probabilities. Neural networks, however powerful, are "black boxes" &mdash; they give you an answer but can't tell you how confident you should be in a rigorous statistical sense. It's like having a brilliant colleague who always gives the right answer but can never explain their reasoning. In everyday life, you'd trust them. In physics, where a wrong claim about a discovery could mislead the entire field, that's not enough. You need the math to back it up.</p>
    </div>

    <div class="commentary-section">
      <h4>The Mass Gap Mystery</h4>
      <p>Neutron stars top out at about 1.4 solar masses. Black holes start at about 6 solar masses. Nothing should exist in between &mdash; it's a "mass gap" predicted by theory. But LIGO has now detected several events involving objects in this forbidden range. Are they measurement errors? A new class of exotic objects? Evidence that our theories about stellar collapse are incomplete? Nobody knows yet, and it's one of the most intriguing open puzzles from LIGO's data.</p>
    </div>

    <div class="commentary-section">
      <h4>The Sociological Divide</h4>
      <p>One of the most revealing moments in the Q&A is when an audience member mentions polling cosmologists about whether they'd trust AI-assisted results: just over half said no, they wouldn't believe it no matter what. Barish sees this as a transition point &mdash; the community is splitting roughly 50/50 on whether to accept new computational methods. This isn't just a technical problem; it's a cultural one within the physics community.</p>
    </div>

    <div class="definition-box">
      <strong>Multi-Messenger Astronomy:</strong> Observing the same cosmic event using multiple types of signals &mdash; gravitational waves, electromagnetic radiation (light, radio, X-rays, gamma rays), and potentially neutrinos. Each "messenger" provides different information, and combining them gives a far richer understanding than any single observation method alone.
    </div>

    <div class="definition-box">
      <strong>Kilonova:</strong> An astronomical event that occurs when two neutron stars (or a neutron star and a black hole) collide and merge. Unlike a supernova (the collapse of a single star), a kilonova is powered by the radioactive decay of heavy elements freshly synthesized in the collision. It is now considered the primary source of elements heavier than iron in the universe, including gold and platinum.
    </div>

    <div class="definition-box">
      <strong>Five Sigma (Statistical Significance):</strong> The gold standard in physics for claiming a discovery. "Five sigma" means there is only a 1-in-3.5-million probability that the observed result is a statistical fluke caused by random noise. This extremely high bar exists because extraordinary claims &mdash; like the discovery of a new particle or gravitational waves &mdash; require extraordinary evidence. It is calculated using traditional statistical methods, which is why the "black box" nature of neural networks poses a problem.
    </div>

    <div class="definition-box">
      <strong>Mass Gap:</strong> The theoretically predicted absence of compact objects between about 1.4 and 6 solar masses. Neutron stars cannot exceed roughly 1.4 solar masses without collapsing further, and the lightest black holes predicted by stellar collapse models are about 6 solar masses. LIGO has detected several events with objects falling in this "forbidden" range, challenging existing models.
    </div>

    <div class="warning-box">
      <strong>Core Tension &mdash; AI Power vs. Scientific Rigor:</strong> Barish articulates a fundamental conflict at the heart of AI's role in physics. Neural networks and machine learning are demonstrably powerful &mdash; they can classify particles, process signals, and identify patterns faster and sometimes more accurately than traditional methods. But physics demands more than correct answers: it demands quantified confidence. The five-sigma standard requires knowing the precise probability that a result is real, and black-box models cannot provide that. Until AI methods can be connected to rigorous statistical frameworks &mdash; until the "black box" can explain not just what it found but how certain it is &mdash; physicists will continue to use AI only in supporting roles (speed, engineering, optimization) rather than as the tool that makes the discovery itself. As Barish puts it, AI and statistical significance are "basically allergic to each other." Bridging that gap is one of the great open challenges at the intersection of AI and fundamental science.
    </div>
  </div>
</div>
