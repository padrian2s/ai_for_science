<div class="page-content">
  <h2>Section 4: Tao &mdash; Q&amp;A: The Future of AI in Math</h2>

  <div class="transcript">
    <span class="speaker speaker--host">Moderator:</span>
    <p>Well, thank you so much. We have time for a few questions.</p>

    <span class="speaker speaker--host">Audience Member:</span>
    <p>Your last conclusion was that AI use is highly situational. We're at a point in time now. Do you think that's what it looks like five or ten years from now?</p>

    <span class="speaker speaker--guest">Terry Tao:</span>
    <p>The question is, in five years, will AI use cases still be highly situational? I think technically yes, but I think we will have figured out how to use it. Maybe an analogy is with Wikipedia. When Wikipedia first came out, there was this brief period when, as a lecturer, you would see students just dump Wikipedia pages into their homework, clearly not understanding what's going on. The initial reaction was, "Oh, we should ban the use of Wikipedia." But we eventually realized that Wikipedia is a situational tool. You don't use it to get the final answer to anything, but it's a good starting point &mdash; it gives you other references, and you should still use your own judgment. Now no one forbids people from using Wikipedia, because we've understood how to use it properly and how not to use it. Technically, Wikipedia is still a situational tool, but it's no longer an issue.</p>

    <p>I think AI will go the same way. There are obvious, really bad ways to use AI that we're seeing right now, and we still need to educate ourselves as a community about that. I think in five years we will just have a good cultural understanding of what AI can and can't do, and we won't have this issue of having to distinguish between good and bad uses of AI as much.</p>

    <span class="speaker speaker--host">Audience Member:</span>
    <p>These are problems, and they're well known. But as you said, there are some hard problems. Let's say Green's theorem, which you proved. Would AI be able to prove it?</p>

    <span class="speaker speaker--guest">Terry Tao:</span>
    <p>That Green's theorem I proved &mdash; that is one of the Erd&#337;s problems, I forget the number. To date, there have been scans where people have gone through each one of the thousand problems and fed them to an AI, and they get like a one or two percent success rate &mdash; which is already amazingly impressive. But to date, with the current level of technology, the one or two percent they do solve are the ones that have not been studied very intensively, and the solutions are relatively short and standard.</p>

    <p>Now, for problems that have been solved by some difficult method &mdash; if the method is in the literature, sometimes AI can recover it. But so far we have not had a really striking use of these tools to solve a problem using a technique that no one has seen before. That's where we are right now.</p>

    <span class="speaker speaker--host">Audience Member:</span>
    <p>What about formulating conjectures?</p>

    <span class="speaker speaker--guest">Terry Tao:</span>
    <p>That's a good question. This site doesn't accept new conjectures unless they came from Erd&#337;s. But it is potentially a good use case. The thing is, it's much harder to score. A problem you can solve or not solve &mdash; that's a scoring function, and AI is pretty good at optimizing scoring functions. But a conjecture could be useful or not useful. You can generate random conjectures, but for a genuinely useful conjecture, we don't have a good scoring function.</p>

    <p>In the near term, I think what will happen is that humans can form conjectures and AIs can critique them &mdash; try to disprove them, test them against standard examples, give you some feedback. But not yet autonomously producing good conjectures. That would be a great development.</p>

    <span class="speaker speaker--host">Audience Member:</span>
    <p>You mentioned how AI is helping with medium-hard problems in math. What about the connections of math to physics or biology? So far it's been quite difficult to establish collaborations. It would be wonderful if mathematicians could get involved in this kind of applied math.</p>

    <span class="speaker speaker--guest">Terry Tao:</span>
    <p>We are having some IPAM events. Next month we're bringing together physicists and mathematicians to try exactly that. AI should be helpful &mdash; certainly for explaining basic concepts. If I'm working with a physicist and I don't understand what quantum field theory is, I can say, "Explain it to me like I'm a mathematician." That does help.</p>

    <p>One thing, though, is that AI has been particularly useful in mathematics because we have this ability to verify everything we say, and that filters out a lot of the rubbish. The moment you move to other sciences, you still have some verification, but it is not as watertight. It should still be possible, and we're going to run various attempts. The concept of broader participation in mathematics would also include the other sciences &mdash; getting mathematicians to work on projects in physics, chemistry, or biology.</p>

    <span class="speaker speaker--host">Moderator:</span>
    <p>All right. Well, thank you so much.</p>
  </div>

  <div class="commentary">
    <h3>Explained Simply</h3>

    <div class="commentary-section">
      <h4>The Wikipedia Analogy</h4>
      <p>Tao offers a memorable comparison. When Wikipedia first launched, some students began pasting Wikipedia text into their homework, and some teachers wanted to ban it. Over time, people figured out that Wikipedia is a starting point, not a final answer &mdash; you use it to orient yourself, then follow the references and think for yourself. Tao predicts AI will follow the same path. Right now we're in the messy early phase where people sometimes use AI badly (submitting raw AI output as their own work, for example). But within a few years, the academic community will develop shared norms about when and how to use AI, just as it did with Wikipedia. The tool will still be "situational" &mdash; better for some tasks than others &mdash; but that will be well understood and no longer controversial.</p>
    </div>

    <div class="commentary-section">
      <h4>Can AI Prove Hard Theorems?</h4>
      <p>An audience member asks about AI tackling the truly hard problems &mdash; like the Green-Tao theorem (which proves that the prime numbers contain arithmetic progressions of any length). Tao is candid: not yet. When researchers feed all thousand Erd&#337;s problems to AI, the success rate is about one to two percent. That sounds low, but it is genuinely impressive &mdash; it means AI can independently solve around ten to twenty real mathematical problems. The catch is that the problems it solves are the ones that haven't received much human attention and have short, standard solutions. For the famous, deep problems that required novel techniques, AI has not yet demonstrated the ability to find a new approach that no human has seen before. This is the current frontier.</p>
    </div>

    <div class="commentary-section">
      <h4>Why Scoring Conjectures Is Hard</h4>
      <p>The question about conjectures gets at a fundamental asymmetry in mathematics. For <em>problems</em>, the scoring function is binary: solved or not solved. AI systems are excellent at optimizing clear scoring functions. But for <em>conjectures</em>, the value is subjective &mdash; a conjecture might be technically true but mathematically uninteresting, or it might be false but point toward something important. We simply don't have a way to automatically score whether a conjecture is "good." Tao suggests a near-term middle ground: humans generate conjectures, and AI helps critique them by testing examples, looking for counterexamples, and offering feedback. Fully autonomous conjecture generation remains a future goal.</p>
    </div>

    <div class="commentary-section">
      <h4>The Gap Between Medium and Hard Problems</h4>
      <p>A theme running through the entire Q&amp;A is the gap between what AI can do with medium-difficulty problems and what it can do with the hardest ones. For medium problems &mdash; especially those that haven't been studied much &mdash; AI can make real contributions: searching literature, trying standard techniques, generating formal proofs. But the hardest problems in mathematics typically require entirely new ideas, creative leaps, and deep structural insight. AI has not yet demonstrated this kind of originality. Tao is optimistic but realistic: the current tools are powerful for scaling across many problems, not yet for drilling deep into one.</p>
    </div>

    <div class="commentary-section">
      <h4>Math Meets Other Sciences</h4>
      <p>The final question touches on interdisciplinary collaboration. Tao notes that AI can serve as a translator between fields &mdash; helping a mathematician understand physics concepts, or vice versa. But he flags an important caveat: mathematics has a unique advantage in the AI era because it has <em>formal verification</em>. If a proof compiles in Lean, it is correct, period. Other sciences have verification too (experiments, data analysis), but it's not as airtight. This means AI-generated results in physics or biology will need even more careful human oversight. IPAM is actively organizing events to explore these cross-disciplinary collaborations.</p>
    </div>

    <div class="definition-box">
      <strong>Green-Tao Theorem:</strong> A landmark result proved by Ben Green and Terry Tao in 2004, showing that the prime numbers contain arithmetic progressions of arbitrarily long length. For example, 7, 37, 67, 97, 127, 157 is an arithmetic progression of six primes (each 30 apart). The theorem proves such progressions exist at any length, no matter how long. It is one of the most celebrated results in 21st-century mathematics and is referenced here as an example of a deep problem beyond current AI capability.
    </div>

    <div class="definition-box">
      <strong>Scoring Function:</strong> A measurable criterion for evaluating success. In problem-solving, the scoring function is simple: the problem is solved or it isn't. AI thrives when it can optimize against a clear score. For conjectures, there is no equivalent &mdash; "useful" or "interesting" are human judgments that resist automation, which is why AI is better at solving problems than at formulating them.
    </div>

    <div class="definition-box">
      <strong>IPAM (Institute for Pure and Applied Mathematics):</strong> A research institute at UCLA that organizes programs bringing together mathematicians, scientists, and engineers to work on problems at the intersection of mathematics and other fields. The conference where this talk took place is an IPAM event, and Tao references upcoming IPAM programs pairing mathematicians with physicists.
    </div>

    <div class="highlight-box">
      <strong>Key Insight &mdash; The 1&ndash;2% Success Rate:</strong> When all thousand Erd&#337;s problems are fed to current AI systems, about one to two percent get solved. This is simultaneously humbling and remarkable. It's humbling because it means AI fails on 98% of well-posed mathematical problems. It's remarkable because even a 1% hit rate across a thousand problems means ten to twenty genuine mathematical results &mdash; and the rate is climbing. The problems AI solves today are the "attention-bottlenecked" ones that humans never focused on. The open question is whether AI will eventually cross the threshold from solving neglected problems with standard methods to cracking famous problems with novel techniques.
    </div>
  </div>
</div>
